{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Employee Attrition Prediction","metadata":{}},{"cell_type":"markdown","source":"### Step-by-Step Procedure\n\nI.\tExploratory data analysis\n    \n    I.1. General exploration\n\n    I.2. Numerical features\n        I.2.1. Explore and clean Numerical features\n        I.2.2. Missing data of Numerical features\n\n    I.3. Categorical features\n        I.3.1. Explore and clean Categorical features\n        I.3.2. Missing data of Categorical features\n        I.3.3. Transform Categorical features into Binary features (get_dummies)\n\n    I.4. Merge numerical and binary features into one data set\n\nII.\tFeature engineering\n\n\nIII.\tModeling\n\n    III.1. Models and metrics selection\n\n    III.2. Hyperparameters tuning and model optimization\n        III.2.1. Logistic regression\n        III.2.2. DecisionTree Classifier\n        III.2.3. XGBoost Classifier\n        III.2.4. RandomForest Classifier\n\n    III.3. Choosing the best model\n\nIV. Prediction","metadata":{}},{"cell_type":"markdown","source":"# I. Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## I.1. General Exploration / Data Inspection","metadata":{}},{"cell_type":"markdown","source":"### 1.1. Importing necessary packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport statsmodels.formula.api as smf\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\npd.set_option(\"display.max_columns\", 80)\npd.set_option(\"display.max_rows\", 80)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:07.271030Z","iopub.execute_input":"2022-08-09T06:29:07.271464Z","iopub.status.idle":"2022-08-09T06:29:07.278053Z","shell.execute_reply.started":"2022-08-09T06:29:07.271426Z","shell.execute_reply":"2022-08-09T06:29:07.277280Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"markdown","source":"### 1.2. Loading the data sets","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\nprint(data.shape)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:07.285147Z","iopub.execute_input":"2022-08-09T06:29:07.285771Z","iopub.status.idle":"2022-08-09T06:29:07.325805Z","shell.execute_reply.started":"2022-08-09T06:29:07.285731Z","shell.execute_reply":"2022-08-09T06:29:07.324915Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"markdown","source":"### 1.3. Inspecting the data","metadata":{}},{"cell_type":"code","source":"# Checking if missing values\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:07.327459Z","iopub.execute_input":"2022-08-09T06:29:07.327797Z","iopub.status.idle":"2022-08-09T06:29:07.341559Z","shell.execute_reply.started":"2022-08-09T06:29:07.327769Z","shell.execute_reply":"2022-08-09T06:29:07.340817Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"code","source":"# Checking Data distribution.\ndata.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:07.342972Z","iopub.execute_input":"2022-08-09T06:29:07.343373Z","iopub.status.idle":"2022-08-09T06:29:07.433170Z","shell.execute_reply.started":"2022-08-09T06:29:07.343325Z","shell.execute_reply":"2022-08-09T06:29:07.431937Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"code","source":"# Checking number of unique values in each columns\ncount = 1\nfor x in data:\n    print(f'{count}. {x}: {data[x].nunique()}')\n    print(f'{data[x].value_counts()}', end = '\\n----------\\n\\n' )    \n    count += 1","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:07.434890Z","iopub.execute_input":"2022-08-09T06:29:07.435263Z","iopub.status.idle":"2022-08-09T06:29:07.480997Z","shell.execute_reply.started":"2022-08-09T06:29:07.435229Z","shell.execute_reply":"2022-08-09T06:29:07.479925Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"markdown","source":"Things to be noted from above result:\n1. There is imbalance in the data. (In Y-variable, one of the class have very high number than the other.)\n2. EmployeeCount, Over18 and StandardHours are constant variable(All the values in the columns are same) and needed to be dropped.\n3. EmployeeNumber is a unique variable(All the values in the columns are completely different/ Primary key) and needed to be dropped.","metadata":{}},{"cell_type":"code","source":"# Dropping unnecessary columns.\ndata.drop(['EmployeeCount', 'Over18', 'StandardHours', 'EmployeeNumber'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:07.482592Z","iopub.execute_input":"2022-08-09T06:29:07.483543Z","iopub.status.idle":"2022-08-09T06:29:07.490421Z","shell.execute_reply.started":"2022-08-09T06:29:07.483497Z","shell.execute_reply":"2022-08-09T06:29:07.489519Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"data.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:07.491831Z","iopub.execute_input":"2022-08-09T06:29:07.492694Z","iopub.status.idle":"2022-08-09T06:29:07.579290Z","shell.execute_reply.started":"2022-08-09T06:29:07.492660Z","shell.execute_reply":"2022-08-09T06:29:07.578284Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"markdown","source":"## I.2. Numerical Features / Continuous variable","metadata":{}},{"cell_type":"markdown","source":"### 1.2.1. Exploring and Cleaning the continuous features","metadata":{}},{"cell_type":"markdown","source":"#### 1.2.1.1. Extracting Numerical features","metadata":{}},{"cell_type":"code","source":"cont_data = data.select_dtypes(exclude = ['object'] )\ncont_data","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:07.580981Z","iopub.execute_input":"2022-08-09T06:29:07.581663Z","iopub.status.idle":"2022-08-09T06:29:07.604813Z","shell.execute_reply.started":"2022-08-09T06:29:07.581618Z","shell.execute_reply":"2022-08-09T06:29:07.604090Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"markdown","source":"#### 1.2.1.2. Data distribution","metadata":{}},{"cell_type":"code","source":"cont_data.hist(figsize = (25, 30), bins = 50, xlabelsize = 8, ylabelsize = 8)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:07.605763Z","iopub.execute_input":"2022-08-09T06:29:07.606576Z","iopub.status.idle":"2022-08-09T06:29:12.656715Z","shell.execute_reply.started":"2022-08-09T06:29:07.606542Z","shell.execute_reply":"2022-08-09T06:29:12.655787Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"markdown","source":"#### 1.2.1.3. BarPlot","metadata":{}},{"cell_type":"code","source":"for i in cont_data:\n    sns.barplot(y = cont_data[i], x = data['Attrition'])\n    plt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:12.659129Z","iopub.execute_input":"2022-08-09T06:29:12.659484Z","iopub.status.idle":"2022-08-09T06:29:20.037253Z","shell.execute_reply.started":"2022-08-09T06:29:12.659453Z","shell.execute_reply":"2022-08-09T06:29:20.036246Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"markdown","source":"#### 1.2.1.4. Checking for outliers","metadata":{}},{"cell_type":"code","source":"# Using box plot for checking the presence of outliers.\nfor i in cont_data:\n    plt.boxplot(cont_data[i], labels = [i], patch_artist=True)\n    plt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:20.038606Z","iopub.execute_input":"2022-08-09T06:29:20.039017Z","iopub.status.idle":"2022-08-09T06:29:26.457689Z","shell.execute_reply.started":"2022-08-09T06:29:20.038983Z","shell.execute_reply":"2022-08-09T06:29:26.456847Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"markdown","source":"#### patch_artist will show colour inside boxplot. by default it is false so no colour is shown.","metadata":{}},{"cell_type":"markdown","source":"#### Some variables may show outliers here in the boxplot but actually have a meaningful reason for their presence.\n#### So, we will treat outliers only for necessary variable based on our domain understanding.","metadata":{}},{"cell_type":"code","source":"a = ['MonthlyIncome','NumCompaniesWorked', 'TotalWorkingYears', 'YearsInCurrentRole', \n     'TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager']","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:26.459099Z","iopub.execute_input":"2022-08-09T06:29:26.459583Z","iopub.status.idle":"2022-08-09T06:29:26.464641Z","shell.execute_reply.started":"2022-08-09T06:29:26.459550Z","shell.execute_reply":"2022-08-09T06:29:26.463449Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"code","source":"type(a)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:26.465971Z","iopub.execute_input":"2022-08-09T06:29:26.466319Z","iopub.status.idle":"2022-08-09T06:29:26.479676Z","shell.execute_reply.started":"2022-08-09T06:29:26.466289Z","shell.execute_reply":"2022-08-09T06:29:26.478560Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"code","source":"for i in a:\n    sns.histplot(cont_data[i], kde = True, bins = 50, label = cont_data[i].skew())\n    plt.legend(loc = 'upper right')\n    plt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:26.482348Z","iopub.execute_input":"2022-08-09T06:29:26.482939Z","iopub.status.idle":"2022-08-09T06:29:30.215768Z","shell.execute_reply.started":"2022-08-09T06:29:26.482906Z","shell.execute_reply":"2022-08-09T06:29:30.214786Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"markdown","source":"### Skewness is asymmetry in a statistical distribution, in which the curve appears distorted or skewed either to the left or to the right.\nA skewness value greater than 1 or less than -1 indicates a highly skewed distribution. A value between 0.5 and 1 or -0.5 and -1 is moderately skewed. A value between -0.5 and 0.5 indicates that the distribution is fairly symmetrical.\n\n### .skew() function return unbiased skew over requested axis Normalized by N-1\n#### A legend is an area describing the elements of the graph.","metadata":{}},{"cell_type":"code","source":"out_vars = ['MonthlyIncome', 'TotalWorkingYears', 'TrainingTimesLastYear', \n            'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsInCurrentRole', 'YearsWithCurrManager']","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:30.217572Z","iopub.execute_input":"2022-08-09T06:29:30.218059Z","iopub.status.idle":"2022-08-09T06:29:30.222948Z","shell.execute_reply.started":"2022-08-09T06:29:30.218015Z","shell.execute_reply":"2022-08-09T06:29:30.221637Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"markdown","source":"### now i created a function for the treatment of outliers--","metadata":{}},{"cell_type":"code","source":"def outlierTreat(x):\n    upper = x.quantile(.75) + 1.5 * (x.quantile(.75) - x.quantile(.25)) \n    lower = x.quantile(.25) - 1.5 * (x.quantile(.75) - x.quantile(.25))\n    return x.clip(lower, upper)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:30.224809Z","iopub.execute_input":"2022-08-09T06:29:30.225261Z","iopub.status.idle":"2022-08-09T06:29:30.238960Z","shell.execute_reply.started":"2022-08-09T06:29:30.225219Z","shell.execute_reply":"2022-08-09T06:29:30.237998Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"markdown","source":"#### .clip() is used to trim values at specified input threshold. We can use this function to put a lower limit and upper limit on the values that any cell can have in the dataframe","metadata":{}},{"cell_type":"code","source":"cont_data.loc[:, out_vars] = cont_data.loc[:, out_vars].apply(outlierTreat)\ncont_data.loc[:, out_vars] ","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:30.241537Z","iopub.execute_input":"2022-08-09T06:29:30.242547Z","iopub.status.idle":"2022-08-09T06:29:30.317651Z","shell.execute_reply.started":"2022-08-09T06:29:30.242510Z","shell.execute_reply":"2022-08-09T06:29:30.316671Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"# Using box plot for checking the presence of outliers.\nfor i in cont_data:\n    plt.boxplot(cont_data[i], labels = [i])\n    plt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:30.319355Z","iopub.execute_input":"2022-08-09T06:29:30.320020Z","iopub.status.idle":"2022-08-09T06:29:37.146780Z","shell.execute_reply.started":"2022-08-09T06:29:30.319985Z","shell.execute_reply":"2022-08-09T06:29:37.145773Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"markdown","source":"### 1.2.2. Missing value treatment","metadata":{}},{"cell_type":"markdown","source":"#### 1.2.2.1. Checking presence of missing values","metadata":{}},{"cell_type":"code","source":"for i in cont_data:\n    print(f'{i}: {cont_data.shape[0] - cont_data[i].count()}')","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:37.148010Z","iopub.execute_input":"2022-08-09T06:29:37.148360Z","iopub.status.idle":"2022-08-09T06:29:37.155420Z","shell.execute_reply.started":"2022-08-09T06:29:37.148330Z","shell.execute_reply":"2022-08-09T06:29:37.154268Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"markdown","source":"#### The shape attribute for numpy arrays returns the dimensions of the array. If Y has n rows and m columns, then Y.shape is (n,m) . So Y.shape[0] is n .","metadata":{}},{"cell_type":"markdown","source":"**Hence, there are no missing values for Continuous variables.\nNow, we plot a heatmap to visualize for multi-collinearity. However, we will be using other statistical method to remove multi-collinearity.******","metadata":{}},{"cell_type":"code","source":"# Finding the correlation.\ncorr = cont_data.corr()\n\n# Setting the size of figure.\nplt.rcParams['figure.figsize'] = (25, 25)\n\n# Argument Trimming out the values above the main diagonal.\nmask = np.triu(corr)\n\n# Setting low correlation value to 0.\ncorr[(corr.values < 0.3) & (corr.values > -0.3)] = 0\n\n# Plotting the heatmap.\nsns.heatmap(corr, annot = True, fmt = '.2f', mask = mask)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:37.156653Z","iopub.execute_input":"2022-08-09T06:29:37.157082Z","iopub.status.idle":"2022-08-09T06:29:38.782497Z","shell.execute_reply.started":"2022-08-09T06:29:37.157040Z","shell.execute_reply":"2022-08-09T06:29:38.781398Z"},"trusted":true},"execution_count":251,"outputs":[]},{"cell_type":"markdown","source":"### A correlation heatmap is a rectangular representation of data and it repeats the same data description twice because the categories are repeated on both axis for computing analysis. Hence, the same result is obtained twice. A correlation heatmap that presents data only once without repetition that is categories are correlated only once is known as a triangle correlation heatmap. \n\n### Since data is symmetric across the diagonal from left-top to right bottom the idea of obtaining a triangle correlation heatmap is to remove data above it so that it is depicted only once. The elements on the diagonal are the parts where categories of the same type correlate.","metadata":{}},{"cell_type":"markdown","source":"#### We will be keeping notes of these collinear variables.\n#### Later after combining the categorical variables, we'll be dropping out multi-collinearity.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## I.3. Categorical Featues","metadata":{}},{"cell_type":"markdown","source":"### 1.3.1. Exploring and Cleaning the Categorical features","metadata":{}},{"cell_type":"markdown","source":"#### 1.3.1.1. Extracting Categorical features","metadata":{}},{"cell_type":"code","source":"cat_vars = data.select_dtypes(include = ['object'])\ncat_vars","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:38.784535Z","iopub.execute_input":"2022-08-09T06:29:38.784979Z","iopub.status.idle":"2022-08-09T06:29:38.803525Z","shell.execute_reply.started":"2022-08-09T06:29:38.784942Z","shell.execute_reply":"2022-08-09T06:29:38.802780Z"},"trusted":true},"execution_count":252,"outputs":[]},{"cell_type":"code","source":"# Looking at the data distribution for different values.\nplt.rcParams['figure.figsize'] = (6, 4)\nfor i in cat_vars:\n    sns.countplot(x = cat_vars[i],palette=\"rainbow\")\n    plt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:38.804831Z","iopub.execute_input":"2022-08-09T06:29:38.805189Z","iopub.status.idle":"2022-08-09T06:29:40.214372Z","shell.execute_reply.started":"2022-08-09T06:29:38.805159Z","shell.execute_reply":"2022-08-09T06:29:40.213651Z"},"trusted":true},"execution_count":253,"outputs":[]},{"cell_type":"code","source":"# Count values of different values for each variables.\nfor i in cat_vars:\n    print(cat_vars[i].value_counts(), end = '\\n---------\\n\\n')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:40.215474Z","iopub.execute_input":"2022-08-09T06:29:40.216300Z","iopub.status.idle":"2022-08-09T06:29:40.229789Z","shell.execute_reply.started":"2022-08-09T06:29:40.216267Z","shell.execute_reply":"2022-08-09T06:29:40.228887Z"},"trusted":true},"execution_count":254,"outputs":[]},{"cell_type":"code","source":"# The values in the features contains some special characters which are being replaced by '_'(underscore).","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:40.230825Z","iopub.execute_input":"2022-08-09T06:29:40.231478Z","iopub.status.idle":"2022-08-09T06:29:40.240596Z","shell.execute_reply.started":"2022-08-09T06:29:40.231443Z","shell.execute_reply":"2022-08-09T06:29:40.239781Z"},"trusted":true},"execution_count":255,"outputs":[]},{"cell_type":"code","source":"cat_vars.BusinessTravel = np.where(cat_vars.BusinessTravel == 'Non-Travel', 'Non_Travel', cat_vars.BusinessTravel)\n\ncat_vars.Department = np.where(cat_vars.Department == 'Research & Development',\n                               'Research_and_Development', cat_vars.Department)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:40.245583Z","iopub.execute_input":"2022-08-09T06:29:40.246438Z","iopub.status.idle":"2022-08-09T06:29:40.253379Z","shell.execute_reply.started":"2022-08-09T06:29:40.246399Z","shell.execute_reply":"2022-08-09T06:29:40.252496Z"},"trusted":true},"execution_count":256,"outputs":[]},{"cell_type":"code","source":"def func(var):\n    m = list()\n    for i in var:\n        x = i.split(\" \")\n        if len(x) > 1:\n            m.append('_'.join(x))\n        else:\n            m.append(i)\n    return m","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:40.254593Z","iopub.execute_input":"2022-08-09T06:29:40.255084Z","iopub.status.idle":"2022-08-09T06:29:40.263380Z","shell.execute_reply.started":"2022-08-09T06:29:40.255053Z","shell.execute_reply":"2022-08-09T06:29:40.262539Z"},"trusted":true},"execution_count":257,"outputs":[]},{"cell_type":"markdown","source":"#### split() method in Python split a string into a list of strings after breaking the given string by the specified separator. gfg","metadata":{}},{"cell_type":"code","source":"cat_vars = cat_vars.apply(func)\ncat_vars","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:40.264444Z","iopub.execute_input":"2022-08-09T06:29:40.265230Z","iopub.status.idle":"2022-08-09T06:29:40.301211Z","shell.execute_reply.started":"2022-08-09T06:29:40.265191Z","shell.execute_reply":"2022-08-09T06:29:40.300205Z"},"trusted":true},"execution_count":258,"outputs":[]},{"cell_type":"code","source":"# Count values of different values for each variables.\nfor i in cat_vars:\n    print(cat_vars[i].value_counts(), end = '\\n---------\\n\\n')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:40.302214Z","iopub.execute_input":"2022-08-09T06:29:40.303134Z","iopub.status.idle":"2022-08-09T06:29:40.321900Z","shell.execute_reply.started":"2022-08-09T06:29:40.303080Z","shell.execute_reply":"2022-08-09T06:29:40.320637Z"},"trusted":true},"execution_count":259,"outputs":[]},{"cell_type":"markdown","source":"### 1.3.2. Handling Missing values.","metadata":{}},{"cell_type":"markdown","source":"#### 1.3.2.1. Looking for presense of missing values.","metadata":{}},{"cell_type":"code","source":"cat_vars.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:40.323232Z","iopub.execute_input":"2022-08-09T06:29:40.323653Z","iopub.status.idle":"2022-08-09T06:29:40.337194Z","shell.execute_reply.started":"2022-08-09T06:29:40.323621Z","shell.execute_reply":"2022-08-09T06:29:40.336072Z"},"trusted":true},"execution_count":260,"outputs":[]},{"cell_type":"markdown","source":"#### There are no null values. So no need to worry about it. If null values were present, use mode imputation.","metadata":{}},{"cell_type":"markdown","source":"### 1.3.3. Transforming categorical variables.","metadata":{}},{"cell_type":"markdown","source":"#### 1.3.3.1. Creating Dummies for Categorical variables.","metadata":{}},{"cell_type":"code","source":"cat_data = cat_vars.copy()","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:40.339235Z","iopub.execute_input":"2022-08-09T06:29:40.340248Z","iopub.status.idle":"2022-08-09T06:29:40.349451Z","shell.execute_reply.started":"2022-08-09T06:29:40.340198Z","shell.execute_reply":"2022-08-09T06:29:40.348664Z"},"trusted":true},"execution_count":261,"outputs":[]},{"cell_type":"code","source":"cat_data = pd.get_dummies(cat_data, drop_first = True)\n# cat_data.drop(['Attrition_No'], axis = 1, inplace = True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:40.351027Z","iopub.execute_input":"2022-08-09T06:29:40.351992Z","iopub.status.idle":"2022-08-09T06:29:40.370581Z","shell.execute_reply.started":"2022-08-09T06:29:40.351955Z","shell.execute_reply":"2022-08-09T06:29:40.369625Z"},"trusted":true},"execution_count":262,"outputs":[]},{"cell_type":"code","source":"# Finding the correlation.\ncorr = cat_data.corr()\n\n# Setting the size of figure.\nplt.rcParams['figure.figsize'] = (25, 25)\n\n# Argument Trimming out the values above the main diagonal.\nmask = np.triu(corr)\n\n# Setting low correlation value to 0.\ncorr[(corr.values < 0.3) & (corr.values > -0.3)] = 0\n\n# Plotting the heatmap.\nsns.heatmap(corr, annot = True, fmt = '.2f', mask = mask)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:40.371869Z","iopub.execute_input":"2022-08-09T06:29:40.372309Z","iopub.status.idle":"2022-08-09T06:29:42.052348Z","shell.execute_reply.started":"2022-08-09T06:29:40.372277Z","shell.execute_reply":"2022-08-09T06:29:42.051428Z"},"trusted":true},"execution_count":263,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I.4. Merging numerical and categorical variables.","metadata":{}},{"cell_type":"code","source":"# Combining Numerical and Categorical data.\nfinal_data = pd.concat([cont_data, cat_data], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:42.053839Z","iopub.execute_input":"2022-08-09T06:29:42.054331Z","iopub.status.idle":"2022-08-09T06:29:42.062761Z","shell.execute_reply.started":"2022-08-09T06:29:42.054288Z","shell.execute_reply":"2022-08-09T06:29:42.061783Z"},"trusted":true},"execution_count":264,"outputs":[]},{"cell_type":"code","source":"final_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:42.063925Z","iopub.execute_input":"2022-08-09T06:29:42.064261Z","iopub.status.idle":"2022-08-09T06:29:42.099074Z","shell.execute_reply.started":"2022-08-09T06:29:42.064231Z","shell.execute_reply":"2022-08-09T06:29:42.098189Z"},"trusted":true},"execution_count":265,"outputs":[]},{"cell_type":"code","source":"# Finding the correlation.\ncorr = final_data.corr()\n\n# Setting the size of figure.\nplt.rcParams['figure.figsize'] = (25, 25)\n\n# Argument Trimming out the values above the main diagonal.\nmask = np.triu(corr)\n\n# Setting low correlation value to 0.\ncorr[(corr.values < 0.3) & (corr.values > -0.3)] = 0\n\n# Plotting the heatmap.\nsns.heatmap(corr, annot = True, fmt = '.2f', mask = mask)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:42.100458Z","iopub.execute_input":"2022-08-09T06:29:42.101040Z","iopub.status.idle":"2022-08-09T06:29:46.877841Z","shell.execute_reply.started":"2022-08-09T06:29:42.101004Z","shell.execute_reply":"2022-08-09T06:29:46.876799Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering and Feature Selection (Finding and dropping multi-collinear varibles)","metadata":{}},{"cell_type":"markdown","source":"### For classification based problems, we can either use VIF or Somers'D for finding the important varibles for the model.\n### VIF helps to decrease multi-collinearity, whereas Somers'D helps to find the variable that increases the predictive power of my model.","metadata":{}},{"cell_type":"code","source":"# Importing packages for discovering muti-collinear features\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom patsy import dmatrices","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:46.879181Z","iopub.execute_input":"2022-08-09T06:29:46.879539Z","iopub.status.idle":"2022-08-09T06:29:46.884396Z","shell.execute_reply.started":"2022-08-09T06:29:46.879507Z","shell.execute_reply":"2022-08-09T06:29:46.883438Z"},"trusted":true},"execution_count":267,"outputs":[]},{"cell_type":"markdown","source":"#### What is Patsy in Python?\n#### patsy is a Python package for describing statistical models (especially linear models, or models that have a linear component) and building design matrices.","metadata":{}},{"cell_type":"markdown","source":"# VIF","metadata":{}},{"cell_type":"code","source":"# Separating X features from dataset and creating a model-parameter for statistical model building.\nfeature_columns = final_data.columns.difference(['Attrition_Yes'])\nmodel_params = 'Attrition_Yes ~ ' + ' + '.join(feature_columns)\nmodel_params","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:46.885643Z","iopub.execute_input":"2022-08-09T06:29:46.886016Z","iopub.status.idle":"2022-08-09T06:29:46.900280Z","shell.execute_reply.started":"2022-08-09T06:29:46.885986Z","shell.execute_reply":"2022-08-09T06:29:46.899278Z"},"trusted":true},"execution_count":268,"outputs":[]},{"cell_type":"code","source":"y, X = dmatrices(model_params, final_data, return_type = 'dataframe')","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:46.902095Z","iopub.execute_input":"2022-08-09T06:29:46.902866Z","iopub.status.idle":"2022-08-09T06:29:46.974130Z","shell.execute_reply.started":"2022-08-09T06:29:46.902822Z","shell.execute_reply":"2022-08-09T06:29:46.973413Z"},"trusted":true},"execution_count":269,"outputs":[]},{"cell_type":"markdown","source":"#### patsy.dmatrix    Construct a single design matrix given a formula_like and data.\n#### patsy.dmatrices(formula_like, data, return_type)  Construct two design matrices given a formula_like and data.\n#### This function is identical to dmatrix(), except that it requires (and returns) two matrices instead of one. By convention, the first matrix is the “outcome” or “y” data, and the second is the “predictor” or “x” data.\n\n\n\n\n####  What is design matrix in machine learning?\n####  Design matrix: A collection of feature vectors for different data points constitutes a design matrix. Each row of the matrix is one data point (i.e., one feature vector), and each column represents the values of a given feature across all of the data points","metadata":{}},{"cell_type":"code","source":"# Finding the VIF values and creating a dataframe to store these values corresponding to features name.\nmul = pd.DataFrame()\nmul['Features'] = X.columns\n\nmul['VIF_values'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nmul","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:46.975294Z","iopub.execute_input":"2022-08-09T06:29:46.976142Z","iopub.status.idle":"2022-08-09T06:29:47.336179Z","shell.execute_reply.started":"2022-08-09T06:29:46.976108Z","shell.execute_reply":"2022-08-09T06:29:47.334906Z"},"trusted":true},"execution_count":270,"outputs":[]},{"cell_type":"code","source":"# Finding the variables based on the cut-off value for VIF.\n# Theoretically, the value should be more than 5 but practically it is taken as more than 4.\n# However, any value (4 or 5) is correct based on the business problems.\n\nf_data = mul[mul.VIF_values > 5].reset_index(drop = True)\nf_data","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:47.337995Z","iopub.execute_input":"2022-08-09T06:29:47.338840Z","iopub.status.idle":"2022-08-09T06:29:47.364185Z","shell.execute_reply.started":"2022-08-09T06:29:47.338780Z","shell.execute_reply":"2022-08-09T06:29:47.362848Z"},"trusted":true},"execution_count":271,"outputs":[]},{"cell_type":"code","source":"# Finding the correlation.\ncorr = final_data[f_data.Features[1:]].corr()\n\n# Setting the size of figure.\nplt.rcParams['figure.figsize'] = (25, 25)\n\n# Argument Trimming out the values above the main diagonal.\nmask = np.triu(corr)\n\n# Setting low correlation value to 0.\ncorr[(corr.values < 0.3) & (corr.values > -0.3)] = 0\n\n# Plotting the heatmap.\nsns.heatmap(corr, annot = True, fmt = '.2f', mask = mask)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:47.365980Z","iopub.execute_input":"2022-08-09T06:29:47.367122Z","iopub.status.idle":"2022-08-09T06:29:48.301674Z","shell.execute_reply.started":"2022-08-09T06:29:47.367071Z","shell.execute_reply":"2022-08-09T06:29:48.300721Z"},"trusted":true},"execution_count":272,"outputs":[]},{"cell_type":"markdown","source":"### We can either use VIF or Somers Delta method for feature engineering and feature selection.\n### In vif we have to remove the columns having vif above 5(cut off value) and so we drop f_data from our final data and then use that data for modelling.","metadata":{}},{"cell_type":"markdown","source":"## Somers' D Score","metadata":{}},{"cell_type":"markdown","source":"#### refer https://www.statisticshowto.com/somers-d/","metadata":{}},{"cell_type":"code","source":"# Separating X features from dataset and creating a model-parameter for statistical model building.\nfeature_columns = final_data.columns.difference(['Attrition_Yes'])\nfeature_columns","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:48.303289Z","iopub.execute_input":"2022-08-09T06:29:48.303743Z","iopub.status.idle":"2022-08-09T06:29:48.312674Z","shell.execute_reply.started":"2022-08-09T06:29:48.303687Z","shell.execute_reply":"2022-08-09T06:29:48.311671Z"},"trusted":true},"execution_count":273,"outputs":[]},{"cell_type":"code","source":"# Finding out the Somers'D value foreach variables.\ncol = list()\nscore = list()\nfor i in feature_columns:\n    model_params = f'Attrition_Yes ~ {i}'\n    log_reg = smf.logit(model_params, final_data).fit()\n    somersD = 2 * metrics.roc_auc_score(final_data['Attrition_Yes'], log_reg.predict(final_data)) - 1   \n    col.append(i)\n    score.append(somersD)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:48.314426Z","iopub.execute_input":"2022-08-09T06:29:48.314929Z","iopub.status.idle":"2022-08-09T06:29:48.817224Z","shell.execute_reply.started":"2022-08-09T06:29:48.314885Z","shell.execute_reply":"2022-08-09T06:29:48.816254Z"},"trusted":true},"execution_count":274,"outputs":[]},{"cell_type":"code","source":"# Making a dataframe for Somers'D score for different variables.\nsom = {'Column_name' : col,\n        'SomersD_value' : score}\nf_vars = pd.DataFrame(som)\nf_vars","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:48.818540Z","iopub.execute_input":"2022-08-09T06:29:48.818888Z","iopub.status.idle":"2022-08-09T06:29:48.835803Z","shell.execute_reply.started":"2022-08-09T06:29:48.818858Z","shell.execute_reply":"2022-08-09T06:29:48.834781Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"code","source":"# Taking the cut-off value for Somers'D as 0.1\nf_vars1 = f_vars[f_vars.SomersD_value >= 0.1]","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:48.837451Z","iopub.execute_input":"2022-08-09T06:29:48.838079Z","iopub.status.idle":"2022-08-09T06:29:48.846046Z","shell.execute_reply.started":"2022-08-09T06:29:48.838010Z","shell.execute_reply":"2022-08-09T06:29:48.845050Z"},"trusted":true},"execution_count":276,"outputs":[]},{"cell_type":"code","source":"print(len(f_vars1.Column_name))\nf_vars1.Column_name","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:48.847472Z","iopub.execute_input":"2022-08-09T06:29:48.847855Z","iopub.status.idle":"2022-08-09T06:29:48.863209Z","shell.execute_reply.started":"2022-08-09T06:29:48.847824Z","shell.execute_reply":"2022-08-09T06:29:48.862362Z"},"trusted":true},"execution_count":277,"outputs":[]},{"cell_type":"code","source":"# Taking the cut-off value for Somers'D as 0.2\nf_vars2 = f_vars[f_vars.SomersD_value >= 0.2]","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:48.864859Z","iopub.execute_input":"2022-08-09T06:29:48.865232Z","iopub.status.idle":"2022-08-09T06:29:48.870733Z","shell.execute_reply.started":"2022-08-09T06:29:48.865200Z","shell.execute_reply":"2022-08-09T06:29:48.869932Z"},"trusted":true},"execution_count":278,"outputs":[]},{"cell_type":"code","source":"print(len(f_vars2.Column_name))\nf_vars2.Column_name","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:48.872193Z","iopub.execute_input":"2022-08-09T06:29:48.872512Z","iopub.status.idle":"2022-08-09T06:29:48.886691Z","shell.execute_reply.started":"2022-08-09T06:29:48.872483Z","shell.execute_reply":"2022-08-09T06:29:48.886004Z"},"trusted":true},"execution_count":279,"outputs":[]},{"cell_type":"markdown","source":"Ideally the cut-off value for Somers'D score should be greater than 0.2 but when we use this cut-off value, thw number of variables become very less. Thus, we use 0.1 kepping in mind that this may result in some prediction error.","metadata":{}},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"markdown","source":"#### from    sklearn.model_selection    import train_test_split, GridSearchCV\n#### from    sklearn.feature_selection  import RFE\n#### from    sklearn.linear_model       import LogisticRegression\n#### from    sklearn                    import metrics\n#### import  statsmodels.formula.api    as smf\n\n#### (Already done above in importing necessary packages)","metadata":{}},{"cell_type":"code","source":"Model = list()\nAccuracy = list()\nAUC_score = list()","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:48.888250Z","iopub.execute_input":"2022-08-09T06:29:48.888599Z","iopub.status.idle":"2022-08-09T06:29:48.894243Z","shell.execute_reply.started":"2022-08-09T06:29:48.888567Z","shell.execute_reply":"2022-08-09T06:29:48.893476Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"markdown","source":"## ML Models","metadata":{}},{"cell_type":"code","source":"# Separating dependent and independent variables from final_data on the basis of Somers'D score\nX = final_data[f_vars1.Column_name]\ny = final_data['Attrition_Yes']","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:48.895679Z","iopub.execute_input":"2022-08-09T06:29:48.896268Z","iopub.status.idle":"2022-08-09T06:29:48.913311Z","shell.execute_reply.started":"2022-08-09T06:29:48.896229Z","shell.execute_reply":"2022-08-09T06:29:48.912278Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"X.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:48.914941Z","iopub.execute_input":"2022-08-09T06:29:48.915337Z","iopub.status.idle":"2022-08-09T06:29:48.926532Z","shell.execute_reply.started":"2022-08-09T06:29:48.915303Z","shell.execute_reply":"2022-08-09T06:29:48.925838Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"code","source":"# Train-Test split for building ML models.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 12345)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:48.927749Z","iopub.execute_input":"2022-08-09T06:29:48.929553Z","iopub.status.idle":"2022-08-09T06:29:48.938948Z","shell.execute_reply.started":"2022-08-09T06:29:48.929489Z","shell.execute_reply":"2022-08-09T06:29:48.938022Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:48.940563Z","iopub.execute_input":"2022-08-09T06:29:48.941051Z","iopub.status.idle":"2022-08-09T06:29:48.950545Z","shell.execute_reply.started":"2022-08-09T06:29:48.941008Z","shell.execute_reply":"2022-08-09T06:29:48.949602Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"markdown","source":"### 1. ML based Logistic Regression","metadata":{}},{"cell_type":"code","source":"Model.append('ML_Log_reg')\nlog_reg = LogisticRegression(max_iter = 5000)\nlog_reg.fit(X_train, y_train)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:29:48.951777Z","iopub.execute_input":"2022-08-09T06:29:48.952376Z","iopub.status.idle":"2022-08-09T06:29:49.837364Z","shell.execute_reply.started":"2022-08-09T06:29:48.952342Z","shell.execute_reply":"2022-08-09T06:29:49.836157Z"},"trusted":true},"execution_count":285,"outputs":[]},{"cell_type":"code","source":"# Find the Accuracy score of the model.\naccuracy = metrics.accuracy_score(y_test, log_reg.predict(X_test))\nAccuracy.append(accuracy)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:49.839442Z","iopub.execute_input":"2022-08-09T06:29:49.840787Z","iopub.status.idle":"2022-08-09T06:29:49.860408Z","shell.execute_reply.started":"2022-08-09T06:29:49.840724Z","shell.execute_reply":"2022-08-09T06:29:49.858907Z"},"trusted":true},"execution_count":286,"outputs":[]},{"cell_type":"code","source":"# Find the AUC score of the model.\nauc = metrics.roc_auc_score(y_test, log_reg.predict(X_test))\nAUC_score.append(auc)\nauc","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:49.867390Z","iopub.execute_input":"2022-08-09T06:29:49.871401Z","iopub.status.idle":"2022-08-09T06:29:49.896435Z","shell.execute_reply.started":"2022-08-09T06:29:49.871327Z","shell.execute_reply":"2022-08-09T06:29:49.895064Z"},"trusted":true},"execution_count":287,"outputs":[]},{"cell_type":"markdown","source":"### 2. Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:49.904237Z","iopub.execute_input":"2022-08-09T06:29:49.908130Z","iopub.status.idle":"2022-08-09T06:29:49.917877Z","shell.execute_reply.started":"2022-08-09T06:29:49.908058Z","shell.execute_reply":"2022-08-09T06:29:49.916094Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"# Using GridSearchCv to cross-validate the model and find the value of hyper-parameters.\nparam_grid = {'max_depth' : range(2, 15)}\n\ntree_clf = GridSearchCV(DecisionTreeClassifier(), param_grid, cv = 10, n_jobs = -1, verbose = 1)\ntree_clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:49.919403Z","iopub.execute_input":"2022-08-09T06:29:49.920293Z","iopub.status.idle":"2022-08-09T06:29:52.063621Z","shell.execute_reply.started":"2022-08-09T06:29:49.920246Z","shell.execute_reply":"2022-08-09T06:29:52.062756Z"},"trusted":true},"execution_count":289,"outputs":[]},{"cell_type":"code","source":"tree_clf.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:52.064934Z","iopub.execute_input":"2022-08-09T06:29:52.065388Z","iopub.status.idle":"2022-08-09T06:29:52.071992Z","shell.execute_reply.started":"2022-08-09T06:29:52.065353Z","shell.execute_reply":"2022-08-09T06:29:52.071015Z"},"trusted":true},"execution_count":290,"outputs":[]},{"cell_type":"code","source":"# Creating the model using best estimator after CV.\nModel.append('DTree')\ntree_clf = tree_clf.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:52.073333Z","iopub.execute_input":"2022-08-09T06:29:52.074274Z","iopub.status.idle":"2022-08-09T06:29:52.082431Z","shell.execute_reply.started":"2022-08-09T06:29:52.074210Z","shell.execute_reply":"2022-08-09T06:29:52.081727Z"},"trusted":true},"execution_count":291,"outputs":[]},{"cell_type":"code","source":"# Find the Accuracy score of the model.\naccuracy = metrics.accuracy_score(y_test, tree_clf.predict(X_test))\nAccuracy.append(accuracy)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:52.083948Z","iopub.execute_input":"2022-08-09T06:29:52.084681Z","iopub.status.idle":"2022-08-09T06:29:52.098995Z","shell.execute_reply.started":"2022-08-09T06:29:52.084636Z","shell.execute_reply":"2022-08-09T06:29:52.098030Z"},"trusted":true},"execution_count":292,"outputs":[]},{"cell_type":"code","source":"# Find the AUC score of the model.\nauc = metrics.roc_auc_score(y_test, tree_clf.predict(X_test))\nAUC_score.append(auc)\nauc","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:52.100803Z","iopub.execute_input":"2022-08-09T06:29:52.101268Z","iopub.status.idle":"2022-08-09T06:29:52.113969Z","shell.execute_reply.started":"2022-08-09T06:29:52.101225Z","shell.execute_reply":"2022-08-09T06:29:52.112899Z"},"trusted":true},"execution_count":293,"outputs":[]},{"cell_type":"markdown","source":"### 3. Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn import ensemble as en","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:52.115266Z","iopub.execute_input":"2022-08-09T06:29:52.115759Z","iopub.status.idle":"2022-08-09T06:29:52.121517Z","shell.execute_reply.started":"2022-08-09T06:29:52.115695Z","shell.execute_reply":"2022-08-09T06:29:52.120656Z"},"trusted":true},"execution_count":294,"outputs":[]},{"cell_type":"code","source":"# Using GridSearchCv to cross-validate the model and find the value of hyper-parameters.\n\nparam_grid = {'n_estimators' : [20, 30, 40, 50, 60, 70, 80, 90, 100], \n                 'max_features' : range(2, 15)}\n\nrf_clf = en.RandomForestClassifier()\nrf_clf = GridSearchCV(rf_clf, param_grid, cv = 5, n_jobs = -1, scoring = 'roc_auc', verbose = 1)\nrf_clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:29:52.123114Z","iopub.execute_input":"2022-08-09T06:29:52.123995Z","iopub.status.idle":"2022-08-09T06:30:29.602806Z","shell.execute_reply.started":"2022-08-09T06:29:52.123962Z","shell.execute_reply":"2022-08-09T06:30:29.601941Z"},"trusted":true},"execution_count":295,"outputs":[]},{"cell_type":"code","source":"rf_clf.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:29.603856Z","iopub.execute_input":"2022-08-09T06:30:29.604166Z","iopub.status.idle":"2022-08-09T06:30:29.609400Z","shell.execute_reply.started":"2022-08-09T06:30:29.604138Z","shell.execute_reply":"2022-08-09T06:30:29.608760Z"},"trusted":true},"execution_count":296,"outputs":[]},{"cell_type":"code","source":"# Creating the model using best estimator after CV.\nModel.append('RForest')\nrf_clf = rf_clf.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:29.610473Z","iopub.execute_input":"2022-08-09T06:30:29.611362Z","iopub.status.idle":"2022-08-09T06:30:29.621874Z","shell.execute_reply.started":"2022-08-09T06:30:29.611327Z","shell.execute_reply":"2022-08-09T06:30:29.620591Z"},"trusted":true},"execution_count":297,"outputs":[]},{"cell_type":"code","source":"# Find the Accuracy score of the model.\naccuracy = metrics.accuracy_score(y_test, rf_clf.predict(X_test))\nAccuracy.append(accuracy)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:29.623240Z","iopub.execute_input":"2022-08-09T06:30:29.624197Z","iopub.status.idle":"2022-08-09T06:30:29.658748Z","shell.execute_reply.started":"2022-08-09T06:30:29.624141Z","shell.execute_reply":"2022-08-09T06:30:29.657687Z"},"trusted":true},"execution_count":298,"outputs":[]},{"cell_type":"code","source":"# Find the AUC score of the model.\nauc = metrics.roc_auc_score(y_test, rf_clf.predict(X_test))\nAUC_score.append(auc)\nauc","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:29.660361Z","iopub.execute_input":"2022-08-09T06:30:29.660816Z","iopub.status.idle":"2022-08-09T06:30:29.689806Z","shell.execute_reply.started":"2022-08-09T06:30:29.660775Z","shell.execute_reply":"2022-08-09T06:30:29.689061Z"},"trusted":true},"execution_count":299,"outputs":[]},{"cell_type":"markdown","source":"### 4. Gradient Boosting","metadata":{}},{"cell_type":"code","source":"# Using GridSearchCv to cross-validate the model and find the value of hyper-parameters.\n\nparam_grid = {'n_estimators' : [40, 50, 60, 70, 80, 90, 100, 110, 120, 130], \n#               'learning_rate' : [10 ** x for x in range(-3, 2)],\n                 'max_features' : range(2, 15)}\n\ngb_clf = en.GradientBoostingClassifier()\ngb_clf = GridSearchCV(gb_clf, param_grid, cv = 5, n_jobs = -1, scoring = 'roc_auc', verbose = 1)\ngb_clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:29.690763Z","iopub.execute_input":"2022-08-09T06:30:29.691581Z","iopub.status.idle":"2022-08-09T06:30:58.111516Z","shell.execute_reply.started":"2022-08-09T06:30:29.691549Z","shell.execute_reply":"2022-08-09T06:30:58.110275Z"},"trusted":true},"execution_count":300,"outputs":[]},{"cell_type":"code","source":"gb_clf.best_params_","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:30:58.119298Z","iopub.execute_input":"2022-08-09T06:30:58.119711Z","iopub.status.idle":"2022-08-09T06:30:58.126632Z","shell.execute_reply.started":"2022-08-09T06:30:58.119662Z","shell.execute_reply":"2022-08-09T06:30:58.125499Z"},"trusted":true},"execution_count":301,"outputs":[]},{"cell_type":"code","source":"# Creating the model using best estimator after CV.\nModel.append('GBoost')\ngb_clf = gb_clf.best_estimator_","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:30:58.128192Z","iopub.execute_input":"2022-08-09T06:30:58.128636Z","iopub.status.idle":"2022-08-09T06:30:58.136914Z","shell.execute_reply.started":"2022-08-09T06:30:58.128596Z","shell.execute_reply":"2022-08-09T06:30:58.135981Z"},"trusted":true},"execution_count":302,"outputs":[]},{"cell_type":"code","source":"# Find the Accuracy score of the model.\naccuracy = metrics.accuracy_score(y_test, gb_clf.predict(X_test))\nAccuracy.append(accuracy)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:58.138119Z","iopub.execute_input":"2022-08-09T06:30:58.138470Z","iopub.status.idle":"2022-08-09T06:30:58.156368Z","shell.execute_reply.started":"2022-08-09T06:30:58.138441Z","shell.execute_reply":"2022-08-09T06:30:58.155226Z"},"trusted":true},"execution_count":303,"outputs":[]},{"cell_type":"code","source":"# Find the AUC score of the model.\nauc = metrics.roc_auc_score(y_test, gb_clf.predict(X_test))\nAUC_score.append(auc)\nauc","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:58.158090Z","iopub.execute_input":"2022-08-09T06:30:58.158835Z","iopub.status.idle":"2022-08-09T06:30:58.173668Z","shell.execute_reply.started":"2022-08-09T06:30:58.158792Z","shell.execute_reply":"2022-08-09T06:30:58.172528Z"},"trusted":true},"execution_count":304,"outputs":[]},{"cell_type":"markdown","source":"### 5. Xtreme Gradient Boosting","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRFClassifier","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:58.175353Z","iopub.execute_input":"2022-08-09T06:30:58.176076Z","iopub.status.idle":"2022-08-09T06:30:58.181547Z","shell.execute_reply.started":"2022-08-09T06:30:58.176032Z","shell.execute_reply":"2022-08-09T06:30:58.180827Z"},"trusted":true},"execution_count":305,"outputs":[]},{"cell_type":"code","source":"# # Using GridSearchCv to cross-validate the model and find the value of hyper-parameters.\n\n#param_grid = {'n_estimators' : [20, 30, 40, 50, 60, 70, 80], \n#              'learning_rate' : [10 ** x for x in range(-3, 2)]}\n\n#xgb_clf = XGBRFClassifier(use_label_encoder=False, objective='reg:squarederror')\n#xgb_clf = GridSearchCV(xgb_clf, param_grid, cv = 5, n_jobs = -1, scoring = 'roc_auc', verbose = 1)\n#xgb_clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:32:37.463046Z","iopub.execute_input":"2022-08-09T06:32:37.463477Z","iopub.status.idle":"2022-08-09T06:32:37.468550Z","shell.execute_reply.started":"2022-08-09T06:32:37.463437Z","shell.execute_reply":"2022-08-09T06:32:37.467416Z"},"trusted":true},"execution_count":308,"outputs":[]},{"cell_type":"code","source":" # xgb_clf.best_params_","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:30:58.197643Z","iopub.status.idle":"2022-08-09T06:30:58.198851Z","shell.execute_reply.started":"2022-08-09T06:30:58.198538Z","shell.execute_reply":"2022-08-09T06:30:58.198567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Creating the model using best estimator after CV.\n# Model.append('XGBoost')\n# xgb_clf = xgb_clf.best_estimator_","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-09T06:30:58.200405Z","iopub.status.idle":"2022-08-09T06:30:58.201107Z","shell.execute_reply.started":"2022-08-09T06:30:58.200835Z","shell.execute_reply":"2022-08-09T06:30:58.200861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross-validating wasn't giving any better output than without CV. Hence, CV was not used(done).","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:58.202441Z","iopub.status.idle":"2022-08-09T06:30:58.203150Z","shell.execute_reply.started":"2022-08-09T06:30:58.202878Z","shell.execute_reply":"2022-08-09T06:30:58.202906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model.append('XGBoost')\nxgb_clf = XGBRFClassifier(use_label_encoder=False, objective='reg:squarederror')\nxgb_clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:32:45.205114Z","iopub.execute_input":"2022-08-09T06:32:45.205801Z","iopub.status.idle":"2022-08-09T06:32:45.398929Z","shell.execute_reply.started":"2022-08-09T06:32:45.205736Z","shell.execute_reply":"2022-08-09T06:32:45.397736Z"},"trusted":true},"execution_count":309,"outputs":[]},{"cell_type":"code","source":"# Find the Accuracy score of the model.\naccuracy = metrics.accuracy_score(y_test, xgb_clf.predict(X_test))\nAccuracy.append(accuracy)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:32:48.881903Z","iopub.execute_input":"2022-08-09T06:32:48.882920Z","iopub.status.idle":"2022-08-09T06:32:48.905830Z","shell.execute_reply.started":"2022-08-09T06:32:48.882856Z","shell.execute_reply":"2022-08-09T06:32:48.904686Z"},"trusted":true},"execution_count":310,"outputs":[]},{"cell_type":"code","source":"# Find the AUC score of the model.\nauc = metrics.roc_auc_score(y_test, xgb_clf.predict(X_test))\nAUC_score.append(auc)\nauc","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:32:52.470613Z","iopub.execute_input":"2022-08-09T06:32:52.471147Z","iopub.status.idle":"2022-08-09T06:32:52.495355Z","shell.execute_reply.started":"2022-08-09T06:32:52.471104Z","shell.execute_reply":"2022-08-09T06:32:52.494205Z"},"trusted":true},"execution_count":311,"outputs":[]},{"cell_type":"code","source":"# Looking at outcoems for all different models.\ncomp = {\n    'Model' : Model,\n    'AUC_score' : AUC_score,\n    'Accuracy' : Accuracy\n}\npd.DataFrame(comp)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:32:56.450953Z","iopub.execute_input":"2022-08-09T06:32:56.451442Z","iopub.status.idle":"2022-08-09T06:32:56.466637Z","shell.execute_reply.started":"2022-08-09T06:32:56.451406Z","shell.execute_reply":"2022-08-09T06:32:56.465626Z"},"trusted":true},"execution_count":312,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Have A Great Day.","metadata":{}},{"cell_type":"markdown","source":"# EOF","metadata":{}},{"cell_type":"markdown","source":"# ----Further improvements----","metadata":{}},{"cell_type":"markdown","source":"1. Use of RFE for feature elimination.\n2. Handling Imbalance data Using RandomSampling, SMOTE and SMOTETomek approaches","metadata":{}},{"cell_type":"code","source":"# from sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:58.213377Z","iopub.status.idle":"2022-08-09T06:30:58.214184Z","shell.execute_reply.started":"2022-08-09T06:30:58.213895Z","shell.execute_reply":"2022-08-09T06:30:58.213923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rfe = RFE(DecisionTreeClassifier(random_state = 1234), n_features_to_select = 15)\n# rfe.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:58.215382Z","iopub.status.idle":"2022-08-09T06:30:58.215819Z","shell.execute_reply.started":"2022-08-09T06:30:58.215606Z","shell.execute_reply":"2022-08-09T06:30:58.215626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features = X.columns[rfe.support_]\n# X = X[features]\n# features","metadata":{"execution":{"iopub.status.busy":"2022-08-09T06:30:58.217636Z","iopub.status.idle":"2022-08-09T06:30:58.218486Z","shell.execute_reply.started":"2022-08-09T06:30:58.218199Z","shell.execute_reply":"2022-08-09T06:30:58.218228Z"},"trusted":true},"execution_count":null,"outputs":[]}]}